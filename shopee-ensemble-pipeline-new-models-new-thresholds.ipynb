{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"ls /kaggle/input/shopee-utils-updated/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datetime import datetime,timedelta\nstart_time = datetime.now()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nimport os\nimport pandas as pd\nimport gc\nsys.path.insert(0,'../input/shopee-utils-updated-0-9/')\ntest_df = pd.read_csv('../input/shopee-product-matching/test.csv')\ntest_df['image_path'] = '../input/shopee-product-matching/test_images/'+ test_df.image\nSIMULATE = False\nif test_df.shape[0]<5 and SIMULATE:\n    train_df1 = pd.read_csv('../input/shopee-product-matching/train.csv')\n    train_df2 = pd.read_csv('../input/shopee-product-matching/train.csv')\n    train_df1['posting_id'] += 'a'\n    train_df2['posting_id'] += 'b'\n    test_df = pd.concat([train_df1,train_df2]).reset_index(drop=True)\n    test_df['image_path'] = '../input/shopee-product-matching/train_images/'+ test_df.image\n    del train_df1,train_df2\n    gc.collect()\nprint(test_df.shape)\ntest_df.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if SIMULATE:\n    images_path = '../input/shopee-product-matching/train_images/'\nelse:\n    images_path = '../input/shopee-product-matching/test_images/'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from numba import cuda \ndevice = cuda.get_current_device()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Image Models - EFFICIENTNET","metadata":{}},{"cell_type":"code","source":"!pip install -U /kaggle/input/kerasapplications -q\n!pip install -U /kaggle/input/efficientnet/efficientnet-master -q","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from shopee_image_utils import *","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE = [640,640]\nN_CLASSES = 11014\nKNN = min(50,test_df.shape[0])\nmodel_weights = {\n    '../input/shopee-arcface-training-new-640/EF0_fold0_epoch15.h5':1,\n    '../input/shopee-arcface-full-data-b2/EF2_fold0_epoch14.h5':1,\n    '../input/shopee-arcface-full-data/EF0_fold0_epoch13.h5':1,\n    '../input/shopee-arcface-training-new-b1/EF1_fold0_epoch15.h5':1,\n}\nIMAGE_SIZES = {\n    '../input/shopee-arcface-training-new-640/EF0_fold0_epoch15.h5':[640,640],\n    '../input/shopee-arcface-full-data-b2/EF2_fold0_epoch14.h5':[512,512],\n    '../input/shopee-arcface-full-data/EF0_fold0_epoch13.h5':[512,512],\n    '../input/shopee-arcface-training-new-b1/EF1_fold0_epoch15.h5':[512,512],\n}\nfor file in model_weights:\n    assert os.path.exists(file)\neff_neighbours = get_image_neighbours(model_weights, test_df, IMAGE_SIZES=IMAGE_SIZES, KNN=KNN)\neff_neighbours.columns = ['posting_id1','posting_id2','eff_distance']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device.reset()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eff_neighbours.to_csv('/tmp/eff_neighbours.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del eff_neighbours\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\n\nlocal_vars = list(locals().items())\nfor var, obj in local_vars:\n    print(var, sys.getsizeof(obj))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(datetime.now()-start_time)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Image Models - NFNET","metadata":{}},{"cell_type":"code","source":"# from shopee_nfnet_utils import *","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class Config1:\n    \n#     DATA_DIR = images_path\n#     TEST_CSV = test_df\n    \n#     MODEL_PATH = '../input/shopee-nfnet-models/eca_nfnet_mish_8217.pt'\n\n#     IMG_SIZE = 512\n#     MEAN = [0.485, 0.456, 0.406]\n#     STD = [0.229, 0.224, 0.225]\n#     BATCH_SIZE = 48\n\n#     NUM_WORKERS = 4\n#     DEVICE = 'cuda'\n\n#     CLASSES = 11014\n#     SCALE = 30 \n#     MARGIN = 0.5\n\n#     MODEL_NAME = 'eca_nfnet_l0'\n#     FC_DIM = 512\n\n#     pool = 'gem' #['adaptive2d', 'gem', 'identity']\n#     optimizer = 'adamw' # ['adamw', 'sgd', 'fused_sgd', 'ranger']\n#     p_trainable = True\n#     weight_decay = 0\n#     mish = True\n#     use_fc = True\n# Config2 = None","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class Config2:\n    \n#     DATA_DIR = images_path\n#     TEST_CSV = test_df\n    \n#     MODEL_PATH = '../input/shopee-nfnet-models/eca_nfnet_mish_false_8205.pt'\n\n#     IMG_SIZE = 512\n#     MEAN = [0.485, 0.456, 0.406]\n#     STD = [0.229, 0.224, 0.225]\n#     BATCH_SIZE = 48\n\n#     NUM_WORKERS = 4\n#     DEVICE = 'cuda'\n\n#     CLASSES = 11014\n#     SCALE = 30 \n#     MARGIN = 0.5\n\n#     MODEL_NAME = 'eca_nfnet_l0'\n#     FC_DIM = 512\n\n#     pool = 'gem' #['adaptive2d', 'gem', 'identity']\n#     optimizer = 'adamw' # ['adamw', 'sgd', 'fused_sgd', 'ranger']\n#     p_trainable = True\n#     weight_decay = 0\n#     mish = False\n#     use_fc = True\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# nfnet_neighbours = get_nfnet_neighbours(Config1,Config2,KNN=KNN)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# nfnet_neighbours.to_csv('/tmp/nfnet_neighbours.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# del nfnet_neighbours,Config1,Config2\n# gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(datetime.now()-start_time)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Clip Model","metadata":{}},{"cell_type":"code","source":"# import sys\n# !cp -r ../input/openai-clip/CLIP/CLIP-main /tmp/\n# # Kaggle likes to unpack .gz files in datasets... so we have to pack it back\n# !gzip -c /tmp/CLIP-main/clip/bpe_simple_vocab_16e6.txt > /tmp/CLIP-main/clip/bpe_simple_vocab_16e6.txt.gz\n# sys.path.append('/tmp/CLIP-main')\n# !pip install ../input/openai-clip/ftfy-5.9/ftfy-5.9 \\\n#              ../input/openai-clip/torch-1.7.1+cu110-cp37-cp37m-linux_x86_64.whl \\\n#              ../input/openai-clip/torchvision-0.8.2+cu110-cp37-cp37m-linux_x86_64.whl \\\n#              ../input/faiss-163/faiss_gpu-1.6.3-cp37-cp37m-manylinux2010_x86_64.whl","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from clip_utils import *","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# clip_model = ClipModel('../input/shopee-clip-vfnet-fold0/model_8.bin',df=test_df,images_path=images_path)\n# clip_neighbours = clip_model.get_neighbours()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# clip_neighbours.to_csv('/tmp/clip_neighbours.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# del clip_model\n# gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# torch.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !nvidia-smi","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(datetime.now()-start_time)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Text Models","metadata":{}},{"cell_type":"code","source":"!pip install -U /kaggle/input/sentence-transformers/sentence-transformers-master/ -q","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from shopee_text_arcface_utils import *\nfrom shopee_text_utils import *","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/shopee-product-matching/train.csv')\nall_label_groups = data.label_group.value_counts().reset_index()\narcface_folds = 11014-(all_label_groups.index%5).value_counts()\narcface_folds.loc[-1] = 11014\ndef get_arcface_model(wt,fold):\n    ############# ArcFace Model\n    model_params = {'n_classes': arcface_folds.loc[fold], #-1 for full data model\n     'model_name': '/kaggle/input/sentence-transformer-models/paraphrase-xlm-r-multilingual-v1/0_Transformer',\n     'pooling': 'clf',\n     'use_fc': False,\n     'fc_dim': 512,\n     'dropout': 0.0,\n     'loss_module': 'arcface',\n     's': 30.0,\n     'margin': 0.5,\n     'ls_eps': 0.0,\n     'theta_zero': 0.785}\n    arface_model_instance = arface_model(model_params,model_weights=wt)\n    return arface_model_instance","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MODELS = [\n    '../input/shopee-sbert-mbml-loss-fold-0/Bert-Shopee-epoch56/epoch56/',\n    '../input/shopee-sbert-mbml-loss-fold-1/Bert-Shopee-epoch56/epoch56/',\n    '../input/shopee-sbert-mbml-loss-fold-2/Bert-Shopee-epoch55/epoch55/',\n    '../input/shopee-sbert-mbml-loss-fold-3/Bert-Shopee-epoch46/epoch46/',\n    '../input/shopee-sbert-mbml-loss-fold-4/Bert-Shopee-epoch57/epoch57/', \n    '../input/shopee-models-mnr-loss-full-data-epoch-69/epoch69/',\n    '../input/shopee-models-mnr-loss-fold-1/epoch60/',\n    '../input/shopee-models-mnr-loss-fold-2/epoch69/',\n    '../input/shopee-models-mnr-loss-fold-4/epoch62/'\n    \n]\nWEIGHTS = []\n\nfor model in MODELS:\n    if 'mbml' in model:\n        WEIGHTS.append(0.6)\n    elif 'mnr' in model:\n        WEIGHTS.append(0.4)\n\nMODELS += [ '../input/shopee-sbert-mbml-loss-full-data/Bert-Shopee-epoch50/epoch50/','../input/shopee-models-mnr-loss-all-folds-epoch-69/epoch69/']\nWEIGHTS += [1.2,0.8]\n\narcface = [\n    '../input/shopee-text-arcface-loss-fold-0/sentence_transfomer_xlm_best_loss_num_epochs_70_arcface.bin',\n    '../input/shopee-text-arcface-loss-fold-1/sentence_transfomer_xlm_best_loss_num_epochs_70_arcface.bin',\n    '../input/shopee-text-arcface-loss-fold-3/sentence_transfomer_xlm_best_loss_num_epochs_70_arcface.bin'\n]\nFOLDS = [0,1,3]\nfor wt,fold in zip(arcface,FOLDS):\n    MODELS.append(get_arcface_model(wt,fold))\n    WEIGHTS.append(1)\nMODELS += [\n    get_arcface_model('../input/shopee-models-arcface-full-data/sentence_transfomer_xlm_best_loss_num_epochs_24.bin',-1)\n]\nWEIGHTS.append(2)\nfor model,wt in zip(MODELS,WEIGHTS):\n    print(model,wt)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(datetime.now()-start_time)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = sbert_ensemble(MODELS,WEIGHTS)\n### Inference on Test\nbert_neighbours = model.get_predictions(test_df,KNN=min(50,test_df.shape[0]),threshold=1)\nprint(bert_neighbours.shape)\nbert_neighbours.columns = ['posting_id1', 'posting_id2', 'bert_distance']\nbert_neighbours.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bert_neighbours.to_csv('/tmp/bert_neighbours.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ndel model, MODELS, bert_neighbours, TOKENIZER,Adam,AdamW,ArcMarginProduct,DataLoader,ShopeeDataset,ShopeeNet,all_label_groups,data\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(datetime.now()-start_time)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from nltk.corpus import stopwords\n# from nltk.tokenize import RegexpTokenizer \n# import os, re, csv, math, codecs\n# import json\n\n# stop_words = set(stopwords.words('english'))\n# stop_words.update(['.', ',', '\"', \"'\", ':', ';', '(', ')', '[', ']', '{', '}'])\n\n# with open(\"../input/english-indonesian-data/indonesian_stopwords.txt\") as f:\n#     id_stop = [line.rstrip('\\n') for line in f]\n    \n# stop_words.update(id_stop)\n\n# with open('../input/english-indonesian-data/id_en_vocab.json', 'r') as fp:\n#     id_en_vocab = json.load(fp)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# USE_CLEAN_TEXT = True\n\n# def preprocess_text(text):\n#     s = str(text).lower()\n#     # replace & with and\n#     s = re.sub('&', ' and ', s)\n#     # replace / with or (idn)\n#     s = re.sub('/', 'atau', s, count=1)\n#     # remove all special characters\n#     s = s = re.sub(r\"[^a-zA-Z0-9]+\", ' ', s)\n#     # replace 's with only s (the special character ' is not the standard one, hence the implementation)\n#     s = re.sub(' s ', 's ', s)\n#     # add whitespace after each number\n#     s = re.sub(r\"([0-9]+(\\.[0-9]+)?)\", r\" \\1 \", s).strip()\n    \n#     return s\n\n# def id_en(t):\n#     if t in id_en_vocab.keys():\n#         return id_en_vocab[t]\n#     else:\n#         return t\n\n# # def preprocess_text\n\n# def remove_stopwords(text):\n#     s = str(text).lower()\n#     s = \" \".join([id_en(word) for word in s.split() if word not in stop_words])\n#     return s\n\n\n# # def remove_stopwords\n\n# def preprocess_row(row, col, func):\n#     return func(row[col])\n\n\n# # def preprocess_row\n\n# def preprocess_text_df(df, txt_cols=['title_1', 'title_2'], func=preprocess_text):\n#     txt_df = df[txt_cols].copy()\n#     for col in txt_cols:\n#         txt_df[col] = txt_df.apply(lambda x: preprocess_row(x, col, func=func), axis=1)\n#     return txt_df\n\n\n# test_df['title'] = preprocess_text_df(test_df, txt_cols=['title'])\n# if USE_CLEAN_TEXT:\n#     test_df['title'] = preprocess_text_df(test_df, txt_cols=['title'], func=remove_stopwords)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf_idf_neighbours = get_tf_idf_predictions(test_df)\ntf_idf_neighbours.columns = ['posting_id1', 'posting_id2', 'tfidf_distance']\nprint(tf_idf_neighbours.shape)\ntf_idf_neighbours.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf_idf_neighbours.to_csv('/tmp/tf_idf_neighbours.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del tf_idf_neighbours,test_df\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\n\nlocal_vars = list(locals().items())\nfor var, obj in local_vars:\n    print(var, sys.getsizeof(obj))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls -lh /tmp/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(datetime.now()-start_time)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Ensemble","metadata":{}},{"cell_type":"code","source":"import dask.dataframe as dd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bert_neighbours = dd.read_csv('/tmp/bert_neighbours.csv')\ntf_idf_neighbours = dd.read_csv('/tmp/tf_idf_neighbours.csv')\ntext_neighbours = dd.merge(bert_neighbours,tf_idf_neighbours,on=['posting_id1','posting_id2'],how='outer').fillna(1)\ntext_neighbours['text_distance'] = (text_neighbours['bert_distance'] + text_neighbours['tfidf_distance'])/2\ndel bert_neighbours,tf_idf_neighbours\ngc.collect()\n\nimage_neighbours = dd.read_csv('/tmp/eff_neighbours.csv')\nimage_neighbours = image_neighbours.rename(columns={'eff_distance':'image_distance'})\n# nfnet_neighbours = dd.read_csv('/tmp/nfnet_neighbours.csv')\n# image_neighbours = dd.merge(eff_neighbours,nfnet_neighbours,on=['posting_id1','posting_id2'],how='outer').fillna(1)\n# image_neighbours['image_distance'] = 0.65*image_neighbours['eff_distance'] + 0.35*image_neighbours['nfnet_distance']\n# del eff_neighbours,eff_neighbours\n# gc.collect()\n\n# clip_neighbours = pd.read_csv('/tmp/clip_neighbours.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# top2_text = text_neighbours.sort_values('text_distance').groupby('posting_id1').head(2).reset_index(drop=True)\n# intersection = pd.merge(image_neighbours,text_neighbours,on=['posting_id1','posting_id2'])\n# intersection = intersection[(intersection.text_distance<0.3)&(intersection.image_distance<0.4)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"neighbours = dd.merge(image_neighbours,text_neighbours,on=['posting_id1','posting_id2'],how='outer').fillna(1)\nneighbours['distance'] = (neighbours.text_distance+neighbours.image_distance)/2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del image_neighbours,text_neighbours\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"neighbours = neighbours[['posting_id1','posting_id2','image_distance','text_distance','distance']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nneighbours = neighbours.compute()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"top2_imtext = neighbours.sort_values('distance').groupby('posting_id1').head(2).reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"neighbours = pd.concat([\n    neighbours[neighbours.distance<0.35],\n    neighbours[neighbours.text_distance<0.18],\n    neighbours[neighbours.image_distance<0.28],\n]).drop_duplicates(['posting_id1','posting_id2'],keep='first')\nneighbours_value_counts = neighbours.posting_id1.value_counts()\nleft_ids = neighbours_value_counts.loc[neighbours_value_counts==1].index.to_list()\nneighbours = pd.concat([neighbours,top2_imtext[top2_imtext.posting_id1.isin(left_ids)]]).drop_duplicates(['posting_id1','posting_id2'],keep='first')\nprint(neighbours.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# neighbours = pd.concat([\n#     text_neighbours[text_neighbours.text_distance<0.2],\n#     top2_text[top2_text.text_distance<0.7],\n#     image_neighbours[image_neighbours.image_distance<0.3],\n#     intersection\n# ]).drop_duplicates(['posting_id1','posting_id2'],keep='first')\n# print(neighbours.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = neighbours.groupby('posting_id1').posting_id2.apply(lambda x:\" \".join(x)).reset_index()\nsubmission_df.columns = ['posting_id','matches']\nsubmission_df.to_csv('submission.csv',index=False)\nsubmission_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}